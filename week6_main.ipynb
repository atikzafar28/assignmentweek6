{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CE-xKtQ-nCLO",
        "outputId": "46915d97-8fa3-4c52-91ef-7f31889200cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Tuning LogisticRegression with GridSearchCV...\n",
            "Best Parameters: {'C': 0.01, 'solver': 'lbfgs'}\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.93      0.85       110\n",
            "           1       0.84      0.59      0.69        69\n",
            "\n",
            "    accuracy                           0.80       179\n",
            "   macro avg       0.81      0.76      0.77       179\n",
            "weighted avg       0.80      0.80      0.79       179\n",
            "\n",
            "\n",
            "üîç Tuning RandomForest with GridSearchCV...\n",
            "Best Parameters: {'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.93      0.85       110\n",
            "           1       0.84      0.61      0.71        69\n",
            "\n",
            "    accuracy                           0.80       179\n",
            "   macro avg       0.82      0.77      0.78       179\n",
            "weighted avg       0.81      0.80      0.80       179\n",
            "\n",
            "\n",
            "üîç Tuning SVC with GridSearchCV...\n",
            "Best Parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.92      0.85       110\n",
            "           1       0.83      0.62      0.71        69\n",
            "\n",
            "    accuracy                           0.80       179\n",
            "   macro avg       0.81      0.77      0.78       179\n",
            "weighted avg       0.81      0.80      0.80       179\n",
            "\n",
            "\n",
            "üìä Model Comparison:\n",
            "                Model  Accuracy  Precision    Recall  F1 Score\n",
            "0                 SVC  0.804469   0.807475  0.804469  0.797746\n",
            "1        RandomForest  0.804469   0.809702  0.804469  0.796632\n",
            "2  LogisticRegression  0.798883   0.804706  0.798883  0.790219\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load Dataset\n",
        "df = pd.read_csv('/content/train (1) (1).csv')\n",
        "\n",
        "# Separate target and features\n",
        "y = df['Survived']\n",
        "X = df.drop('Survived', axis=1)\n",
        "\n",
        "# Drop irrelevant or high-cardinality columns\n",
        "X = X.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
        "\n",
        "# One-hot encode categorical columns\n",
        "X = pd.get_dummies(X, columns=['Sex', 'Embarked'], drop_first=True)\n",
        "\n",
        "# Impute missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Scale the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Define models and hyperparameters\n",
        "models = {\n",
        "    \"LogisticRegression\": {\n",
        "        \"model\": LogisticRegression(max_iter=5000),\n",
        "        \"params\": {\n",
        "            \"C\": [0.01, 0.1, 1, 10],\n",
        "            \"solver\": ['liblinear', 'lbfgs']\n",
        "        }\n",
        "    },\n",
        "    \"RandomForest\": {\n",
        "        \"model\": RandomForestClassifier(random_state=42),\n",
        "        \"params\": {\n",
        "            \"n_estimators\": [50, 100, 200],\n",
        "            \"max_depth\": [None, 5, 10],\n",
        "            \"min_samples_split\": [2, 5]\n",
        "        }\n",
        "    },\n",
        "    \"SVC\": {\n",
        "        \"model\": SVC(),\n",
        "        \"params\": {\n",
        "            \"C\": [0.1, 1, 10],\n",
        "            \"kernel\": ['linear', 'rbf'],\n",
        "            \"gamma\": ['scale', 'auto']\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Cross-validation strategy\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Store results\n",
        "results = []\n",
        "\n",
        "# GridSearchCV for each model\n",
        "for name, mp in models.items():\n",
        "    print(f\"\\nüîç Tuning {name} with GridSearchCV...\")\n",
        "    grid = GridSearchCV(mp[\"model\"], mp[\"params\"], cv=cv, scoring='accuracy', n_jobs=-1)\n",
        "    grid.fit(X_train, y_train)\n",
        "\n",
        "    best_model = grid.best_estimator_\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    # Metrics\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, average='weighted')\n",
        "    rec = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    print(f\"Best Parameters: {grid.best_params_}\")\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "    results.append({\n",
        "        \"Model\": name,\n",
        "        \"Accuracy\": acc,\n",
        "        \"Precision\": prec,\n",
        "        \"Recall\": rec,\n",
        "        \"F1 Score\": f1\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame and display\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nüìä Model Comparison:\")\n",
        "print(results_df.sort_values(by=\"F1 Score\", ascending=False).reset_index(drop=True))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
